---
title: "Exercise Sheet 7"
author: "Maiwen Caudron-Herger ; Carl Herrmann"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
---

We will work with a dataset of tumor expression data of patients with acute myeloid leukemia (AML) or acute lymphocytic leukemia (ALL):

```{r, echo = FALSE}
all.aml = read.delim('http://bioinfo.ipmb.uni-heidelberg.de/crg/datascience3fs/practicals/data/all.aml.cleaned.csv',header=TRUE)
all.aml.anno = read.delim("http://bioinfo.ipmb.uni-heidelberg.de/crg/datascience3fs/practicals/data/all.aml.anno.cleaned.csv", header=TRUE)
#
# we convert all.aml into a data matrix rather than a data.frame
all.aml = data.matrix(all.aml)
i.all = which(all.aml.anno$ALL.AML=='AML') ## we extract the row numbers of the ALL patients
```

# 1. Introduction and Objectives

In the previous Exercise Sheet we have looked at **hypothesis testing**, learned how the process works and then learned about the t-test function.

In this Exercise Sheet you will learn more about hypothesis testing, specifically about how to deal with **non-parametric tests** and **proportion testing**.

You should be familiar with both these problems from the lecture.

# 2. Non-parametric test

What if the data is not normally distributed? In that case, we are no supposed to use the t-test for testing differences between mean values! Let us us see an example.

At the beginning, we checked if the distribution of the data in the samples corresponds to a normal distribution.

Check again the distribution of the expression values for the gene FOSB

```{r}
expression = all.aml['FOSB',]
hist(expression,breaks = 30);qqnorm(expression);qqline(expression)
```

This looks everything but normal! In that case, we cannot apply the t.test, but need to apply a **non-parametric test** called the *Wilcoxon test* (check the lecture notes!). This test is performed not on the *values* (like the t-test) but on the *ranks* of these values (remember the difference between the Pearson's and the Spearman's correlations!)

```{r}
exp.all = all.aml['FOSB',i.all]
exp.aml = all.aml['FOSB',-i.all]
wilcox.test(exp.all,exp.aml)
```

Compare the obtained p-value with the p-value obtained if we would have used the t-test:

```{r}
exp.all = all.aml['FOSB',i.all]
exp.aml = all.aml['FOSB',-i.all]
t.test(exp.all,exp.aml)
```

The p-values are very different!! So is the difference of expression between ALL and AML patients for this gene significant or not taking $\alpha=0.05$?

Here, we **cannot** trust the t-test due to the non-normality of the data! Hence, the correct p-value is the one from the Wilcoxon test.

We will discuss in the **Going further...** section what it means that we cannot trust the p-value of the t-test.

------------------------------------------------------------------------

# 3. Proportion tests

The t-test and wilcoxon tests are **tests of the mean**; we are comparing the means of two samples and looking for significant differences.

But there are other hypothesis that one might want to test, related to the relationship between two categorical variables:

-   is the proportion of men **significantly** higher in the patients from Louisa compared to the ones from Buckingham?
-   is the propotion of smothers in under 18 in Germany **significantly** higher than in other european countries?

The proportion test (Fisher Extact Test or chi2 test) are used to investigate the relationship between 2 categorical variables, starting from a **contingency table**. We will use a dataset with clinical informations about breast cancer patients.

```{r}
dat.brca = read.delim('http://bioinfo.ipmb.uni-heidelberg.de/crg/datascience3fs/practicals/data/gbsg_ba_ca.dat', stringsAsFactors = FALSE)
```

Check which variables in this dataset are categorical/ordinal/numerical. We can now check if there is a significant relationship between some variables. For example, we can verify if the choice of treatment with tamoxifen (variable `hormon`) is related to the pre-/post-monopausal status (variable `meno`)

First, we can build the contingency table table for these 2 variables:

```{r}
## build contingency table
table(dat.brca$meno,dat.brca$hormon)
```

------------------------------------------------------------------------

We can compute the **odds-ratio (OR)** for these two variables:

```{r}
CT = table(dat.brca$meno,dat.brca$hormon)

OR = (CT[1,1]/CT[1,2])/(CT[2,1]/CT[2,2])
OR
```

> How would the odds-ratio look like if you would transpose the matrix?

**SOLUTION**

transposing the matrix does not change the odds ratio! We can verify this in R

```{r}
CT = t(CT)

OR = (CT[1,1]/CT[1,2])/(CT[2,1]/CT[2,2])
OR
```
 You can verify this also from the formula of the odds ratio (see slides!)

------------------------------------------------------------------------


Now we can run the one-sided Fisher Exact Test (FET). The H0/H1 hypothesis are:

-   H0: the odds-ratio is not significantly larger than one
-   H1: the odds-ratio is significantly larger than one

```{r}
## build contingency table
tab = table(dat.brca$meno,dat.brca$hormon)
#
## run the FET
fisher.test(tab,alternative = 'greater')
```

Check if your computation of the odds-ratio is right! Compute also the two 2-sided test:

> Formulate the H0/H1 hypothesis!


**SOLUTION**

H0: The OR is not significantly different from 1
H1: the OR is significantly different from 1

```{r}
fisher.test(tab)
```

We can also use the **chi-square test** to answer the same question. The Chi-square test compares the **observed** number of occurences in the contingency table to the **expected** number of occurences if there was no relationship between the variables.

-   H0: the observed and expected occurences are not significantly different
-   H1: the observed and expected occurences are significantly different

```{r}
chisq.test(tab)
```

Now we want to verify the impact of age on the grade of the tumor. We categorize the patients in under and over 40 year groups, and perform a chi-squared test:

```{r}
## contingency table
tab = table(dat.brca$age>40,dat.brca$grade)
tab
##
chisq.test(tab)
```

We can determine the table of expected counts:

```{r}
tot = apply(tab,2,sum) # this is the total number of occurences in the 3 categories, independently of age
tot

age = apply(tab,1,sum) # this is the total number of persons above/below 40, independently of grade
age
```

```{r}
tot.proportions = tot/sum(tot)

tab.exp = sapply(tot.proportions,function(x) {x*age})
tab.exp
```

> How would you compute the chi-square test statistic using the `tab` and `tab.exp` tables?

**SOLUTION**

```{r}
chisq = sum((tab-tab.exp)^2/tab.exp)
chisq
```


# 4. Power of a test

We have seen that $\alpha$ controls the **False-positive rate**. False positive means seing an difference that is not there...

The other type of error are **False-negatives**, i.e. **not seeing** a difference that actually exists!

Let us imagine the following scenario:

## Hunting penguins in Antarctica...

You have been sent on a research mission in Antarctica, to study two penguin populations: 

1. the King penguins 
2. the Emperor penguins

Both species are similar, but they have different average weight: $w_K = 15\,kg$, $w_E=16\,kg$. The standard deviation for both is $3.5\,kg$

```{r}
wK = 15
wE = 16
s = 3.5
n = 10
```

You are going to an area where **mostly King penguin live**; you are catching 10 penguins a day, weight them, and compute the average weight of the daily sample. Since penguins don't mix, you are always catching individuals from the same species (King or Emperor).

The $H_0$ hypothesis is: *"The penguins caught are King penguins, not Emperor penguins"*

Here are the results of your catch from the first 5 days of your mission

```{r}
mean_weights = c(16.64268,17.69074,15.07522,14.52752,15.76787)
```

What is the expected theoretical distribution of mean weights over samples of $n=10$ penguins?

```{r}
x = seq(12,18,by =0.01)
y = dnorm(x,mean=wK,sd=s/sqrt(n)) 
plot(x,y,type='l',lwd=3,col='red',
main=paste0('Distribution of average weight of King penguins (n=',n,')'))
```

**Note the** $\sqrt{n}$ factor in the standard deviation!!

When would you reject the $H_0$ (one sided test, $\alpha=0.05$)?

```{r}
rej_lim = qnorm(p=0.05,mean=wK,sd=s/sqrt(n),lower.tail = FALSE)
rej_lim
```

Whenever your measured mean weight lies above this, you would reject $H_0$ (so-called **positive** events; otherwise, would not reject $H_0$ (**negative** events).

```{r}
plot(x,y,type='l',lwd=3,col='red',
main=paste0('Distribution of average weight of King penguins (n=',n,')'));
abline(v=rej_lim,lwd=3,lty=3,col='purple');
abline(v=mean_weights,lty=3,lwd=2,col='blue')

```

So day 2 might be a sample of Emperor penguins , but you are pretty confident about the other 4 samples.

However, it turns out that the helicopter wrongly brought you to an area in which there are **only** Emperor penguin living! So all caught samples were composed on Emperor penguins, and $H_0$ is **not valid** for **any** of these 5 samples!

Hence, you failed to reject $H_0$ for 4 out of 5 samples: 80% **false-negatives** !

Let's determine how often that would happen if we consider 1000 samples made of **Emperor penguins**:

```{r}
### parameters
wK = 15
wE = 16
s = 3.5
n = 10

### 1000 samples of n Emperor penguins each
mean_weights  = sapply(1:1000,function(i) {mean(rnorm(n,mean=wE,sd=s))})


### rejection limit for H0 : "samples are King, not Emperor penguins"
rej_lim = qnorm(alpha,mean=wK,sd = s/sqrt(n),lower.tail = FALSE)

### for how many sample did I falsely **not** reject H0?
### H0 ('King penguin') is rejected if the mean weight is ABOVE the rejection limit
### H0 ('King penguin') is NOT rejected if the mean weight is BELOW the rejection limit

beta = sum(mean_weights < rej_lim)/length(mean_weights)
beta

```

This is a huge False-negative rate!!

> How does the false-negative rate beta change with increasing sample size (i.e. increasing n)?
> Try to find a combination of effect size (i.e. difference between the expectation values for the weights), significance level, sample size, so that the beta value is lower than 30% For a given effect size and significance level.

The next code helps visualize what is going on, you can play with the parameters!

```{r}
source('http://bioinfo.ipmb.uni-heidelberg.de/crg/datascience3fs/practicals/helper.R')

wK = 15
wE = 16
s = 3.5
n = 10

h0h1(wK,wE,s,n,alpha)
```
All samples (dots) are drawn from the purple curve (Emperor penguin). The red dots are the ones where the H0 hypothesis "King penguin" ist rejected (correctly), the purple dots are the samples for which H0 is NOT rejected (wrongly). 
 
------------------------------------------------------------------------

# Exercises

#### Exercise 1

1.  Check the expression of a random gene in the ALL/AML dataset. Are the values normally distributed?

```{r}
i.rnd = sample(1:nrow(all.aml),1)
gene.exp = all.aml[i.rnd,]

qqnorm(gene.exp, main=rownames(all.aml)[i.rnd]);qqline(gene.exp)
```


2.  Run both tests on this gene. Is there a difference between p-values? What did you expect?


```{r}
## t-test
t.test(gene.exp[i.all],gene.exp[-i.all])$p.value

## Wilcoxon test
wilcox.test(gene.exp[i.all],gene.exp[-i.all])$p.value

```


3.  Write a code that runs both tests on every gene and registers each p-value in a vector.


```{r, warning=FALSE}
P = apply(all.aml,1,function(x){
  p.t = t.test(x[i.all],x[-i.all])$p.value
  p.w = wilcox.test(x[i.all],x[-i.all])$p.value
  return(c(p.t,p.w))
})
```


4.  Do a scatter plot of -log10(Pvalue of t-test) vs. -log10(Pvalue of wilcoxon test); are there strong deviations?

```{r}
plot(-log10(P[1,]),-log10(P[2,]),pch=20,xlab = '-log10(T-test)',ylab='-log10(Wilcoxon)')
```


#### Exercise 2

What test would you use for the following questions?

-   A lotion company has to figure out whether their last product is more likely to give men acne rather than females

**SOLUTION**: 2 categorical variables (men/women and acne/no-acne), so proportion test (chisquare or fischer)

-   The department of education wants to find out whether social science students have higher grades than natural science students

**SOLUTION** one categorical variable (social science / natural science) but the grades are continuous variables. So t-test or Wilcoxon test would be appropriate!

-   A biologist needs to find out whether a specific gene is more likely to be silenced in lactose intolerant people.

**SOLUTION** two categorical variable (tolerant/intolerant and silenced/non silences) so proportion test (chisquare or fischer)


#### Exercise 3

A pharmaceutical company has a new corona vaccine that works on 178 out of 200 patient. 75% of the batch of patients had been previously vaccinated against corona with another previous vaccine, and on 143 of these did the vaccine work. Is there a significant disproportion to say that the vaccine has a higher chance of working on people who are already vaccinated against corona if our p-value threshold is 0.05?

**SOLUTION**

We have two populations: previously vaccinated or not

```{r}
N = 200
prev_vacc  = N*0.75
non_prev_vacc = N - prev_vacc
```

For the previously vaccinated (n=150 patients), the new vaccine worked for 143 patients, so failed for 7.
For the non-previously vaccinated (50 patients), it hence worked for 35 patients (178-143) and failed for 15 (50-35).
So we can build the following contingency table:

```{r}
M = matrix(c(143,35,7,15),nrow=2,dimnames = list(c('prev vacc','non-prev. vacc'),c('works','fails')))
M
```


We want to test if the new vaccine works better for vaccinated people, so we perform a one-sided test:

```{r}
fisher.test(M,alternative = 'greater')
```


------------------------------------------------------------------------

# Going further

What does it mean, when we say that we cannot trust the t-test when the data is not normaly distributed? Remember that the significance value $\alpha$ represents the **false-positive rate (FPR)**. Hence, with an $\alpha$ of 5%, if $H_0$ is true, we have a 5% risk of rejecting $H_0$ (False-positive).

Let us suppose that the $H_0$ Hypothesis: "The expectation values of two distributions are equal" holds. For example, we can generate 2 random samples, drawn from the same distribution, and perform a t-test. Here, $H_0$ would hold! What would the p-value be? Well, if we perform this 10000 times, we would obtain a uniform distribution:

```{r}
set.seed(123)
alpha = 0.05
p = sapply(1:10000,function(i) {
  x = rnorm(10);y = rnorm(10)
  t.test(x,y)$p.value
})
hist(p,breaks=20);abline(v=alpha,col='red',lwd=3)
```

Approximately 5% of these p-values are smaller than $\alpha$ (see red line):

```{r}
sum(p<alpha)/length(p)
```

These would be **False positives**. So here, we indeed have $\alpha$ = False-positive rate!

This also holds true for different values of $\alpha$:

```{r}
alphas = c(0.01,0.02,0.03,0.04,0.05,0.07,0.1,0.2)
fpr = sapply(alphas,function(alpha) {
  sum(p<alpha)/length(p)
})
plot(alphas,fpr,xlab='alpha',pch=19,col='red');abline(0,1,lwd=2,lty=2,col='lightgrey')
```

Now what if the distributions of values had same expectation values, but were not normaly distributed? Let's sample x and y from a t-Distribution, instead of a normal distribution:

```{r}
p = sapply(1:10000,function(i) {
  x = rt(10,df=1);y = rt(10,df=1)
  t.test(x,y)$p.value
})
hist(p,breaks=20);abline(v=alpha,col='red',lwd=3)
```

No longer a uniform distribution!! How often would we reject $H_0$ here?

```{r}
sum(p<alpha)/length(p)
```

Not exactly $\alpha$ anymore... What if we user different values of $\alpha$?

```{r}
alphas = c(0.01,0.02,0.03,0.04,0.05,0.07,0.1,0.2)
fpr = sapply(alphas,function(alpha) {
  sum(p<alpha)/length(p)
})
plot(alphas,fpr,xlab='alpha',pch=19,col='red');abline(0,1,lwd=2,lty=2,col='lightgrey')
```

So in the case of a non-normal distribution of the data, the false-positive rate (FPR) is no longer equal to the significance level $\alpha$... **Hence, we can no longer control the FPR with** $\alpha$!
